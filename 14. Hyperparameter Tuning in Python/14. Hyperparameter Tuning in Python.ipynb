{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Hyperparameter Tuning in Python**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_1Gk2qA29Nx"
      },
      "source": [
        "## Chapter 1 - Hyperparameters and Parameters\n",
        "> In this introductory chapter you will learn the difference between hyperparameters and parameters. You will practice extracting and analyzing parameters, setting hyperparameter values for several popular machine learning algorithms. Along the way you will learn some best practice tips & tricks for choosing which hyperparameters to tune and what values to set & build learning curves to analyze your hyperparameter choices. This is the Summary of lecture \"Hyperparameter Tuning in Python\", via datacamp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "r0Q_-V3q29Nz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSjYHRhT29Nz"
      },
      "source": [
        "### Introduction\n",
        "- Parameters\n",
        "    - Components of the model learned during the modeling process\n",
        "    - Do not set these manually\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAR4TyvC29N0"
      },
      "source": [
        "### Extracting a Logistic Regression parameter\n",
        "You are now going to practice extracting an important parameter of the logistic regression model. The logistic regression has a few other parameters you will not explore here but you can review them in the [scikit-learn.org](https://scikit-learn.org/) documentation for the `LogisticRegression()` module under 'Attributes'.\n",
        "\n",
        "This parameter is important for understanding the direction and magnitude of the effect the variables have on the target.\n",
        "\n",
        "In this exercise we will extract the coefficient parameter (found in the `coef_` attribute), zip it up with the original column names, and see which variables had the largest positive effect on the target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "idKcz8Cd29N0",
        "outputId": "4fa1dc68-5bd2-44d4-c8fd-7f6445208ef2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_0</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>PAY_5</th>\n",
              "      <th>PAY_6</th>\n",
              "      <th>BILL_AMT1</th>\n",
              "      <th>...</th>\n",
              "      <th>SEX_2</th>\n",
              "      <th>EDUCATION_1</th>\n",
              "      <th>EDUCATION_2</th>\n",
              "      <th>EDUCATION_3</th>\n",
              "      <th>EDUCATION_4</th>\n",
              "      <th>EDUCATION_5</th>\n",
              "      <th>EDUCATION_6</th>\n",
              "      <th>MARRIAGE_1</th>\n",
              "      <th>MARRIAGE_2</th>\n",
              "      <th>MARRIAGE_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20000</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>3913</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>120000</td>\n",
              "      <td>26</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2682</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>90000</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29239</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>50000</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46990</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>50000</td>\n",
              "      <td>57</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8617</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  LIMIT_BAL  AGE  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  BILL_AMT1  \\\n",
              "0   1      20000   24      2      2     -1     -1     -2     -2       3913   \n",
              "1   2     120000   26     -1      2      0      0      0      2       2682   \n",
              "2   3      90000   34      0      0      0      0      0      0      29239   \n",
              "3   4      50000   37      0      0      0      0      0      0      46990   \n",
              "4   5      50000   57     -1      0     -1      0      0      0       8617   \n",
              "\n",
              "   ...  SEX_2  EDUCATION_1  EDUCATION_2  EDUCATION_3  EDUCATION_4  \\\n",
              "0  ...   True        False         True        False        False   \n",
              "1  ...   True        False         True        False        False   \n",
              "2  ...   True        False         True        False        False   \n",
              "3  ...   True        False         True        False        False   \n",
              "4  ...  False        False         True        False        False   \n",
              "\n",
              "   EDUCATION_5  EDUCATION_6  MARRIAGE_1  MARRIAGE_2  MARRIAGE_3  \n",
              "0        False        False        True       False       False  \n",
              "1        False        False       False        True       False  \n",
              "2        False        False       False        True       False  \n",
              "3        False        False        True       False       False  \n",
              "4        False        False        True       False       False  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "credit_card = pd.read_csv('credit-card-full.csv')\n",
        "# To change categorical variable with dummy variables\n",
        "credit_card = pd.get_dummies(credit_card, columns=['SEX', 'EDUCATION', 'MARRIAGE'], drop_first=True)\n",
        "credit_card.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "D767fPRN29N1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = credit_card.drop(['ID', 'default payment next month'], axis=1)\n",
        "y = credit_card['default payment next month']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "7poNHX7Y29N1",
        "outputId": "473ae929-1e08-4f5b-abcd-d94478cac1df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       Variable   Coefficient\n",
            "0     LIMIT_BAL -6.977738e-07\n",
            "1           AGE -2.127848e-02\n",
            "2         PAY_0  1.876894e-01\n",
            "3         PAY_2  1.447560e-01\n",
            "4         PAY_3  1.236060e-01\n",
            "5         PAY_4  1.122687e-01\n",
            "6         PAY_5  1.031810e-01\n",
            "7         PAY_6  9.289733e-02\n",
            "8     BILL_AMT1 -5.627443e-06\n",
            "9     BILL_AMT2  3.634145e-06\n",
            "10    BILL_AMT3  1.024709e-06\n",
            "11    BILL_AMT4 -4.802755e-07\n",
            "12    BILL_AMT5  1.350610e-06\n",
            "13    BILL_AMT6 -1.471955e-06\n",
            "14     PAY_AMT1 -1.708411e-05\n",
            "15     PAY_AMT2 -2.069216e-05\n",
            "16     PAY_AMT3 -3.045951e-06\n",
            "17     PAY_AMT4 -4.689321e-06\n",
            "18     PAY_AMT5 -2.608703e-06\n",
            "19     PAY_AMT6 -3.205912e-06\n",
            "20        SEX_2 -2.366238e-02\n",
            "21  EDUCATION_1 -8.339619e-03\n",
            "22  EDUCATION_2 -6.633597e-03\n",
            "23  EDUCATION_3 -5.410737e-04\n",
            "24  EDUCATION_4 -1.058441e-03\n",
            "25  EDUCATION_5 -2.372281e-03\n",
            "26  EDUCATION_6 -4.097835e-05\n",
            "27   MARRIAGE_1  1.690885e-02\n",
            "28   MARRIAGE_2 -3.576897e-02\n",
            "29   MARRIAGE_3  1.667287e-04\n",
            "  Variable  Coefficient\n",
            "2    PAY_0     0.187689\n",
            "3    PAY_2     0.144756\n",
            "4    PAY_3     0.123606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg_clf = LogisticRegression(max_iter=1000)\n",
        "log_reg_clf.fit(X_train, y_train)\n",
        "\n",
        "# Create a list of original variable names from the training DataFrame\n",
        "original_variables = X_train.columns\n",
        "\n",
        "# Extract the coefficients of the logistic regression estimator\n",
        "model_coefficients = log_reg_clf.coef_[0]\n",
        "\n",
        "# Create a dataframe of the variables and coefficients & print it out\n",
        "coefficient_df = pd.DataFrame({'Variable': original_variables,\n",
        "                               'Coefficient': model_coefficients})\n",
        "print(coefficient_df)\n",
        "\n",
        "# Print out the top 3 positive variables\n",
        "top_three_df = coefficient_df.sort_values(by='Coefficient', axis=0, ascending=False)[0:3]\n",
        "print(top_three_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csKfdZO729N2"
      },
      "source": [
        "### Extracting a Random Forest parameter\n",
        "You will now translate the work previously undertaken on the logistic regression model to a random forest model. A parameter of this model is, for a given tree, how it decided to split at each level.\n",
        "\n",
        "This analysis is not as useful as the coefficients of logistic regression as you will be unlikely to ever explore every split and every tree in a random forest model. However, it is a very useful exercise to peak under the hood at what the model is doing.\n",
        "\n",
        "In this exercise we will extract a single tree from our random forest model, visualize it and programmatically extract one of the splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zfoy2Qv29N2",
        "outputId": "242eefb7-639b-4678-d9e5-13b7af098a58"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import export_graphviz\n",
        "import os\n",
        "import pydot\n",
        "\n",
        "rf_clf = RandomForestClassifier(max_depth=4, criterion='gini', n_estimators=10);\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Extract the 7th (index 6) tree from the random forest\n",
        "chosen_tree = rf_clf.estimators_[6]\n",
        "\n",
        "# Convert tree to dot object\n",
        "export_graphviz(chosen_tree,\n",
        "                out_file='tree6.dot',\n",
        "                feature_names=X_train.columns,\n",
        "                filled=True,\n",
        "                rounded=True)\n",
        "(graph, ) = pydot.graph_from_dot_file('tree6.dot')\n",
        "\n",
        "# Convert dot to png\n",
        "graph.write_png('tree_viz_image.png')\n",
        "\n",
        "# Visualize the graph using the provided image\n",
        "tree_viz_image = plt.imread('tree_viz_image.png')\n",
        "plt.figure(figsize = (16,10))\n",
        "plt.imshow(tree_viz_image, aspect='auto');\n",
        "plt.axis('off')\n",
        "\n",
        "# Extract the parameters and level of the top (index 0) node\n",
        "split_column = chosen_tree.tree_.feature[0]\n",
        "split_column_name = X_train.columns[split_column]\n",
        "split_value = chosen_tree.tree_.threshold[0]\n",
        "\n",
        "# Print out the feature and level\n",
        "print('This node split on feature {}, at a value of {}'.format(split_column_name, split_value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4IPCP_f29N2"
      },
      "source": [
        "### Introducing Hyperparameters\n",
        "- Hyperparameters\n",
        "    - Something you set before the modelling process (need to tune)\n",
        "    - The algorithm does not learn these"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f8JPX1029N3"
      },
      "source": [
        "### Exploring Random Forest Hyperparameters\n",
        "Understanding what hyperparameters are available and the impact of different hyperparameters is a core skill for any data scientist. As models become more complex, there are many different settings you can set, but only some will have a large impact on your model.\n",
        "\n",
        "You will now assess an existing random forest model (it has some bad choices for hyperparameters!) and then make better choices for a new random forest model and assess its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM3pevgn29N3",
        "outputId": "b2de63da-ded7-43d0-f43c-6e8d40a1af1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(n_estimators=5, random_state=42)\n",
            "Confusion Matrix: \n",
            "\n",
            " [[6336  667]\n",
            " [1249  748]] \n",
            " Accuracy Score: \n",
            "\n",
            " 0.7871111111111111\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "rf_clf_old = RandomForestClassifier(min_samples_leaf=1, min_samples_split=2,\n",
        "                                    n_estimators=5, oob_score=False, random_state=42)\n",
        "\n",
        "rf_clf_old.fit(X_train, y_train)\n",
        "rf_old_predictions = rf_clf_old.predict(X_test)\n",
        "\n",
        "# Print out the old estimator, notice which hyperparameter is badly set\n",
        "print(rf_clf_old)\n",
        "\n",
        "# Get confusion matrix & accuracy for the old rf_model\n",
        "print('Confusion Matrix: \\n\\n {} \\n Accuracy Score: \\n\\n {}'.format(\n",
        "    confusion_matrix(y_test, rf_old_predictions),\n",
        "    accuracy_score(y_test, rf_old_predictions)\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxT_7krJ29N3",
        "outputId": "cd29e202-cdb7-4e11-afef-907309caff88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            "\n",
            " [[6638  365]\n",
            " [1235  762]]\n",
            "Accuracy Score: \n",
            "\n",
            " 0.8222222222222222\n"
          ]
        }
      ],
      "source": [
        "# Create a new random forest classifier with better hyperparameters\n",
        "rf_clf_new = RandomForestClassifier(n_estimators=500)\n",
        "\n",
        "# Fit this to the data and obtain predictions\n",
        "rf_new_predictions = rf_clf_new.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "# Assess the new model (using new predictions!)\n",
        "print('Confusion Matrix: \\n\\n', confusion_matrix(y_test, rf_new_predictions))\n",
        "print('Accuracy Score: \\n\\n', accuracy_score(y_test, rf_new_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKNu1et729N3"
      },
      "source": [
        "### Hyperparameters of KNN\n",
        "To apply the concepts learned in the prior exercise, it is good practice to try out learnings on a new algorithm. The k-nearest-neighbors algorithm is not as popular as it used to be but can still be an excellent choice for data that has groups of data that behave similarly. Could this be the case for our credit card users?\n",
        "\n",
        "In this case you will try out several different values for one of the core hyperparameters for the knn algorithm and compare performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "answer form Datacamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of 5, 10, 20 neighbours was 0.7564444444444445, 0.7786666666666666, 0.7812222222222223\n"
          ]
        }
      ],
      "source": [
        "# Build a knn estimator for each value of n_neighbours\n",
        "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_10 = KNeighborsClassifier(n_neighbors=10)\n",
        "knn_20 = KNeighborsClassifier(n_neighbors=20)\n",
        "\n",
        "# Fit each to the training data & produce predictions\n",
        "knn_5_predictions = knn_5.fit(X_train, y_train).predict(X_test)\n",
        "knn_10_predictions = knn_10.fit(X_train, y_train).predict(X_test)\n",
        "knn_20_predictions = knn_20.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "# Get an accuracy score for each of the models\n",
        "knn_5_accuracy = accuracy_score(y_test, knn_5_predictions)\n",
        "knn_10_accuracy = accuracy_score(y_test, knn_10_predictions)\n",
        "knn_20_accuracy = accuracy_score(y_test, knn_20_predictions)\n",
        "print(\"The accuracy of 5, 10, 20 neighbours was {}, {}, {}\".format(knn_5_accuracy, knn_10_accuracy, knn_20_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv7l0XQn29N4"
      },
      "source": [
        "### Setting & Analyzing Hyperparameter Values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbSk6wd429N4"
      },
      "source": [
        "### Automating Hyperparameter Choice\n",
        "Finding the best hyperparameter of interest without writing hundreds of lines of code for hundreds of models is an important efficiency gain that will greatly assist your future machine learning model building.\n",
        "\n",
        "An important hyperparameter for the GBM algorithm is the learning rate. But which learning rate is best for this problem? By writing a loop to search through a number of possibilities, collating these and viewing them you can find the best one.\n",
        "\n",
        "Possible learning rates to try include 0.001, 0.01, 0.05, 0.1, 0.2 and 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkq83FcH29N4",
        "outputId": "cfb02eed-c8fb-48f2-fb77-af1a65d095d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   learning_rate  accuracy\n",
            "0          0.001  0.778111\n",
            "1          0.010  0.823000\n",
            "2          0.050  0.826000\n",
            "3          0.100  0.825556\n",
            "4          0.200  0.823333\n",
            "5          0.500  0.818778\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Set the learning rates & results storage\n",
        "learning_rates = [0.001, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
        "results_list = []\n",
        "\n",
        "# Create the for loop to evaluate model predictions for each learning rate\n",
        "for learning_rate in learning_rates:\n",
        "    model = GradientBoostingClassifier(learning_rate=learning_rate)\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "    # Save the learning rate and accuracy score\n",
        "    results_list.append([learning_rate, accuracy_score(y_test, predictions)])\n",
        "\n",
        "# Gather everything into a DataFrame\n",
        "results_df = pd.DataFrame(results_list, columns=['learning_rate', 'accuracy'])\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJgo_uh529N4"
      },
      "source": [
        "### Building Learning Curves\n",
        "If we want to test many different values for a single hyperparameter it can be difficult to easily view that in the form of a DataFrame. Previously you learned about a nice trick to analyze this. A graph called a 'learning curve' can nicely demonstrate the effect of increasing or decreasing a particular hyperparameter on the final result.\n",
        "\n",
        "Instead of testing only a few values for the learning rate, you will test many to easily see the effect of this hyperparameter across a large range of values. A useful function from NumPy is `np.linspace(start, end, num)` which allows you to create a number of values (`num`) evenly spread within an interval (`start`, `end`) that you specify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-ZEfVOJ29N4",
        "outputId": "7475bc44-887c-493d-c3e1-ace21982cf1a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Set the learning rates & accuracies list\n",
        "learn_rates = np.linspace(0.01, 2, num=30)\n",
        "accuracies = []\n",
        "\n",
        "# Create the for loop\n",
        "for learn_rate in learn_rates:\n",
        "    # Create the model, predictions & save the accuracies as before\n",
        "    model = GradientBoostingClassifier(learning_rate=learn_rate)\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "    accuracies.append(accuracy_score(y_test, predictions))\n",
        "\n",
        "# Plot results\n",
        "plt.plot(learn_rates, accuracies);\n",
        "plt.gca().set(xlabel='learning_rate', ylabel='Accuracy', title='Accuracy for different learning_rates');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRrOfEyJ29N4"
      },
      "source": [
        "You can see that for low values, you get a pretty good accuracy. However once the learning rate pushes much above 1.5, the accuracy starts to drop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 2 - Grid search\n",
        "> This chapter introduces you to a popular automated hyperparameter tuning methodology called Grid Search. You will learn what it is, how it works and practice undertaking a Grid Search using Scikit Learn. You will then learn how to analyze the output of a Grid Search & gain practical experience doing this. This is the Summary of lecture \"Hyperparameter Tuning in Python\", via datacamp.\n",
        "\n",
        "- toc: true \n",
        "- badges: true\n",
        "- comments: true\n",
        "- author: Chanseok Kang\n",
        "- categories: [Python, Datacamp, Machine_Learning]\n",
        "- image: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Introducing Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build Grid Search functions\n",
        "In data science it is a great idea to try building algorithms, models and processes 'from scratch' so you can really understand what is happening at a deeper level. Of course there are great packages and libraries for this work (and we will get to that very soon!) but building from scratch will give you a great edge in your data science work.\n",
        "\n",
        "In this exercise, you will create a function to take in 2 hyperparameters, build models and return results. You will use this function in a future exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "credit_card = pd.read_csv('credit-card-full.csv')\n",
        "# To change categorical variable with dummy variables\n",
        "credit_card = pd.get_dummies(credit_card, columns=['SEX', 'EDUCATION', 'MARRIAGE'], drop_first=True)\n",
        "\n",
        "X = credit_card.drop(['ID', 'default payment next month'], axis=1)\n",
        "y = credit_card['default payment next month']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "answer from datacamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the function\n",
        "def gbm_grid_search(learning_rate, max_depth):\n",
        "\n",
        "\t# Create the model\n",
        "    model = GradientBoostingClassifier(learning_rate=learning_rate, max_depth=max_depth)\n",
        "    \n",
        "    # Use the model to make predictions\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "    \n",
        "    # Return the hyperparameters and score\n",
        "    return([learning_rate, max_depth, accuracy_score(y_test, predictions)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Iteratively tune multiple hyperparameters\n",
        "In this exercise, you will build on the function you previously created to take in 2 hyperparameters, build a model and return the results. You will now use that to loop through some values and then extend this function and loop with another hyperparameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.01, 2, 0.8202222222222222], [0.01, 4, 0.8185555555555556], [0.01, 6, 0.8135555555555556], [0.1, 2, 0.82], [0.1, 4, 0.8194444444444444], [0.1, 6, 0.8168888888888889], [0.5, 2, 0.8155555555555556], [0.5, 4, 0.8001111111111111], [0.5, 6, 0.7881111111111111]]\n"
          ]
        }
      ],
      "source": [
        "# Create the relevant lists\n",
        "results_list = []\n",
        "learn_rate_list = [0.01, 0.1, 0.5]\n",
        "max_depth_list = [2, 4, 6]\n",
        "\n",
        "# Create the for loop\n",
        "for learn_rate in learn_rate_list:\n",
        "    for max_depth in max_depth_list:\n",
        "        results_list.append(gbm_grid_search(learn_rate, max_depth))\n",
        "        \n",
        "# Print the results\n",
        "print(results_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extend the function input\n",
        "def gbm_grid_search_extended(learn_rate, max_depth, subsample):\n",
        "    # Extend the model creation section\n",
        "    model = GradientBoostingClassifier(learning_rate=learn_rate, max_depth=max_depth,\n",
        "                                       subsample=subsample)\n",
        "    \n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "    \n",
        "    # Extend the return part\n",
        "    return([learn_rate, max_depth, subsample, accuracy_score(y_test, predictions)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.01, 2, 0.8214444444444444],\n",
            " [0.01, 4, 0.8198888888888889],\n",
            " [0.01, 6, 0.8172222222222222],\n",
            " [0.1, 2, 0.8205555555555556],\n",
            " [0.1, 4, 0.8204444444444444],\n",
            " [0.1, 6, 0.8204444444444444],\n",
            " [0.5, 2, 0.8188888888888889],\n",
            " [0.5, 4, 0.8042222222222222],\n",
            " [0.5, 6, 0.7894444444444444],\n",
            " [0.01, 2, 0.4, 0.8192222222222222],\n",
            " [0.01, 2, 0.6, 0.8208888888888889],\n",
            " [0.01, 4, 0.4, 0.8183333333333334],\n",
            " [0.01, 4, 0.6, 0.8195555555555556],\n",
            " [0.01, 6, 0.4, 0.8177777777777778],\n",
            " [0.01, 6, 0.6, 0.8196666666666667],\n",
            " [0.1, 2, 0.4, 0.821],\n",
            " [0.1, 2, 0.6, 0.8201111111111111],\n",
            " [0.1, 4, 0.4, 0.8207777777777778],\n",
            " [0.1, 4, 0.6, 0.8196666666666667],\n",
            " [0.1, 6, 0.4, 0.8155555555555556],\n",
            " [0.1, 6, 0.6, 0.8183333333333334],\n",
            " [0.5, 2, 0.4, 0.8128888888888889],\n",
            " [0.5, 2, 0.6, 0.8156666666666667],\n",
            " [0.5, 4, 0.4, 0.7945555555555556],\n",
            " [0.5, 4, 0.6, 0.8065555555555556],\n",
            " [0.5, 6, 0.4, 0.7714444444444445],\n",
            " [0.5, 6, 0.6, 0.7743333333333333]]\n"
          ]
        }
      ],
      "source": [
        "# Create the new list to test\n",
        "subsample_list = [0.4, 0.6]\n",
        "\n",
        "for learn_rate in learn_rate_list:\n",
        "    for max_depth in max_depth_list:\n",
        "        # Extend the for loop\n",
        "        for subsample in subsample_list:\n",
        "            # Extend the results to include the new hyperparameter\n",
        "            results_list.append(gbm_grid_search_extended(learn_rate, max_depth, subsample))\n",
        "            \n",
        "# Print the results\n",
        "pprint(results_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Grid Search with Scikit Learn\n",
        "- Steps in a Grid Search\n",
        "    1. An algorithm to tune the hyperparameters (or estimator)\n",
        "    2. Defining which hyperparameters to tune\n",
        "    3. Defining a range of values for each hyperparameter\n",
        "    4. Setting a cross-validatoin scheme\n",
        "    5. Defining a score function so we can decide which square on our grid was 'the best'\n",
        "    6. Include extra useful information or functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GridSearchCV with Scikit Learn\n",
        "The `GridSearchCV` module from Scikit Learn provides many useful features to assist with efficiently undertaking a grid search. You will now put your learning into practice by creating a `GridSearchCV` object with certain parameters.\n",
        "\n",
        "The desired options are:\n",
        "\n",
        "- A Random Forest Estimator, with the split criterion as 'entropy'\n",
        "- 5-fold cross validation\n",
        "- The hyperparameters `max_depth` (2, 4, 8, 15) and `max_features` ('auto' vs 'sqrt')\n",
        "- Use `roc_auc` to score the models\n",
        "- Use 4 cores for processing in parallel\n",
        "- Ensure you refit the best model and return training scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=5, estimator=RandomForestClassifier(criterion='entropy'),\n",
            "             n_jobs=4,\n",
            "             param_grid={'max_depth': [2, 4, 8, 15],\n",
            "                         'max_features': ['auto', 'sqrt']},\n",
            "             return_train_score=True, scoring='roc_auc')\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create a Random Forest Classifier with specified criterion\n",
        "rf_class = RandomForestClassifier(criterion='entropy')\n",
        "\n",
        "# Create the parametergrid\n",
        "param_grid = {\n",
        "    'max_depth':[2, 4, 8, 15],\n",
        "    'max_features':['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_rf_class = GridSearchCV(\n",
        "    estimator=rf_class,\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=4,\n",
        "    cv=5,\n",
        "    refit=True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "print(grid_rf_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding a grid search output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring the grid search results\n",
        "You will now explore the `cv_results_` property of the GridSearchCV object defined in the video. This is a dictionary that we can read into a pandas DataFrame and contains a lot of useful information about the grid search we just undertook.\n",
        "\n",
        "A reminder of the different column types in this property:\n",
        "\n",
        "- `time_` columns\n",
        "- `param_` columns (one for each hyperparameter) and the singular params column (with all hyperparameter settings)\n",
        "- a `train_score` column for each cv fold including the mean_train_score and std_train_score columns\n",
        "- a `test_score` column for each cv fold including the mean_test_score and std_test_score columns\n",
        "- a `rank_test_score` column with a number from 1 to n (number of iterations) ranking the rows based on their `mean_test_score`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
            "20 fits failed out of a total of 40.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "19 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/codespace/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/home/codespace/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/home/codespace/.local/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/home/codespace/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/codespace/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/home/codespace/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/home/codespace/.local/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/home/codespace/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/home/codespace/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.76545271        nan 0.77062602        nan 0.77959914\n",
            "        nan 0.77782694]\n",
            "  warnings.warn(\n",
            "/home/codespace/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [       nan 0.76811484        nan 0.77764703        nan 0.82980761\n",
            "        nan 0.97360329]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
            "0       0.008394      0.005662         0.000000        0.000000   \n",
            "1       2.391917      0.126908         0.047261        0.007851   \n",
            "2       0.004333      0.003165         0.000000        0.000000   \n",
            "3       4.035311      0.146921         0.049742        0.004109   \n",
            "4       0.004642      0.002176         0.000000        0.000000   \n",
            "5       7.205680      0.164465         0.069315        0.003866   \n",
            "6       0.009042      0.003439         0.000000        0.000000   \n",
            "7      10.174682      2.017540         0.094152        0.036486   \n",
            "\n",
            "  param_max_depth param_max_features  \\\n",
            "0               2               auto   \n",
            "1               2               sqrt   \n",
            "2               4               auto   \n",
            "3               4               sqrt   \n",
            "4               8               auto   \n",
            "5               8               sqrt   \n",
            "6              15               auto   \n",
            "7              15               sqrt   \n",
            "\n",
            "                                      params  split0_test_score  \\\n",
            "0   {'max_depth': 2, 'max_features': 'auto'}                NaN   \n",
            "1   {'max_depth': 2, 'max_features': 'sqrt'}           0.768416   \n",
            "2   {'max_depth': 4, 'max_features': 'auto'}                NaN   \n",
            "3   {'max_depth': 4, 'max_features': 'sqrt'}           0.772087   \n",
            "4   {'max_depth': 8, 'max_features': 'auto'}                NaN   \n",
            "5   {'max_depth': 8, 'max_features': 'sqrt'}           0.782066   \n",
            "6  {'max_depth': 15, 'max_features': 'auto'}                NaN   \n",
            "7  {'max_depth': 15, 'max_features': 'sqrt'}           0.783712   \n",
            "\n",
            "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
            "0                NaN                NaN  ...              NaN             NaN   \n",
            "1           0.768541           0.747843  ...         0.765453        0.009719   \n",
            "2                NaN                NaN  ...              NaN             NaN   \n",
            "3           0.775769           0.752432  ...         0.770626        0.010116   \n",
            "4                NaN                NaN  ...              NaN             NaN   \n",
            "5           0.782138           0.762919  ...         0.779599        0.008779   \n",
            "6                NaN                NaN  ...              NaN             NaN   \n",
            "7           0.779104           0.761317  ...         0.777827        0.009510   \n",
            "\n",
            "   rank_test_score  split0_train_score  split1_train_score  \\\n",
            "0                5                 NaN                 NaN   \n",
            "1                4            0.768324            0.766217   \n",
            "2                5                 NaN                 NaN   \n",
            "3                3            0.777497            0.777186   \n",
            "4                5                 NaN                 NaN   \n",
            "5                1            0.829966            0.831148   \n",
            "6                5                 NaN                 NaN   \n",
            "7                2            0.974648            0.973620   \n",
            "\n",
            "   split2_train_score  split3_train_score  split4_train_score  \\\n",
            "0                 NaN                 NaN                 NaN   \n",
            "1            0.773517            0.768502            0.764014   \n",
            "2                 NaN                 NaN                 NaN   \n",
            "3            0.782052            0.776943            0.774558   \n",
            "4                 NaN                 NaN                 NaN   \n",
            "5            0.830005            0.828884            0.829034   \n",
            "6                 NaN                 NaN                 NaN   \n",
            "7            0.974143            0.972868            0.972737   \n",
            "\n",
            "   mean_train_score  std_train_score  \n",
            "0               NaN              NaN  \n",
            "1          0.768115         0.003156  \n",
            "2               NaN              NaN  \n",
            "3          0.777647         0.002436  \n",
            "4               NaN              NaN  \n",
            "5          0.829808         0.000814  \n",
            "6               NaN              NaN  \n",
            "7          0.973603         0.000731  \n",
            "\n",
            "[8 rows x 22 columns]\n",
            "                                      params\n",
            "0   {'max_depth': 2, 'max_features': 'auto'}\n",
            "1   {'max_depth': 2, 'max_features': 'sqrt'}\n",
            "2   {'max_depth': 4, 'max_features': 'auto'}\n",
            "3   {'max_depth': 4, 'max_features': 'sqrt'}\n",
            "4   {'max_depth': 8, 'max_features': 'auto'}\n",
            "5   {'max_depth': 8, 'max_features': 'sqrt'}\n",
            "6  {'max_depth': 15, 'max_features': 'auto'}\n",
            "7  {'max_depth': 15, 'max_features': 'sqrt'}\n",
            "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
            "5        7.20568      0.164465         0.069315        0.003866   \n",
            "\n",
            "  param_max_depth param_max_features  \\\n",
            "5               8               sqrt   \n",
            "\n",
            "                                     params  split0_test_score  \\\n",
            "5  {'max_depth': 8, 'max_features': 'sqrt'}           0.782066   \n",
            "\n",
            "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
            "5           0.782138           0.762919  ...         0.779599        0.008779   \n",
            "\n",
            "   rank_test_score  split0_train_score  split1_train_score  \\\n",
            "5                1            0.829966            0.831148   \n",
            "\n",
            "   split2_train_score  split3_train_score  split4_train_score  \\\n",
            "5            0.830005            0.828884            0.829034   \n",
            "\n",
            "   mean_train_score  std_train_score  \n",
            "5          0.829808         0.000814  \n",
            "\n",
            "[1 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "grid_rf_class.fit(X_train, y_train)\n",
        "\n",
        "# Read the cv_results property into adataframe & print it out\n",
        "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
        "print(cv_results_df)\n",
        "\n",
        "# Extract and print the column with a dictionary of hyperparameters used\n",
        "column = cv_results_df.loc[:, [\"params\"]]\n",
        "print(column)\n",
        "\n",
        "# Extract and print the row that had the best mean test score\n",
        "best_row = cv_results_df[cv_results_df['rank_test_score'] == 1]\n",
        "print(best_row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyzing the best results\n",
        "At the end of the day, we primarily care about the best performing 'square' in a grid search. Luckily Scikit Learn's `gridSearchCV` objects have a number of parameters that provide key information on just the best square (or row in `cv_results_`).\n",
        "\n",
        "Three properties you will explore are:\n",
        "\n",
        "- `best_score_` â€“ The score (here ROC_AUC) from the best-performing square.\n",
        "- `best_index_` â€“ The index of the row in `cv_results_` containing information on the best-performing square.\n",
        "- `best_params_` â€“ A dictionary of the parameters that gave the best score, for example 'max_depth': 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7795991402464372\n",
            "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
            "5        7.20568      0.164465         0.069315        0.003866   \n",
            "\n",
            "  param_max_depth param_max_features  \\\n",
            "5               8               sqrt   \n",
            "\n",
            "                                     params  split0_test_score  \\\n",
            "5  {'max_depth': 8, 'max_features': 'sqrt'}           0.782066   \n",
            "\n",
            "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
            "5           0.782138           0.762919  ...         0.779599        0.008779   \n",
            "\n",
            "   rank_test_score  split0_train_score  split1_train_score  \\\n",
            "5                1            0.829966            0.831148   \n",
            "\n",
            "   split2_train_score  split3_train_score  split4_train_score  \\\n",
            "5            0.830005            0.828884            0.829034   \n",
            "\n",
            "   mean_train_score  std_train_score  \n",
            "5          0.829808         0.000814  \n",
            "\n",
            "[1 rows x 22 columns]\n",
            "8\n"
          ]
        }
      ],
      "source": [
        "# Print out the ROC_AUC score from the best-performing square\n",
        "best_score = grid_rf_class.best_score_\n",
        "print(best_score)\n",
        "\n",
        "# Create a variable from the row related to the best-performing square\n",
        "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
        "best_row = cv_results_df.loc[[grid_rf_class.best_index_]]\n",
        "print(best_row)\n",
        "\n",
        "# Get the max_depth parameter from the best-performing square and print\n",
        "best_max_depth = grid_rf_class.best_params_['max_depth']\n",
        "print(best_max_depth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using the best results\n",
        "While it is interesting to analyze the results of our grid search, our final goal is practical in nature; we want to make predictions on our test set using our estimator object.\n",
        "\n",
        "We can access this object through the `best_estimator_` property of our grid search object.\n",
        "\n",
        "In this exercise we will take a look inside the `best_estimator_` property and then use this to make predictions on our test set for credit card defaults and generate a variety of scores. Remember to use `predict_proba` rather than `predict` since we need probability values rather than class labels for our roc_auc score. We use a slice `[:,1]` to get probabilities of the positive class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
            "[1 0 0 1 0]\n",
            "Confusion Matrix \n",
            " [[6685  323]\n",
            " [1292  700]]\n",
            "ROC-AUC Score \n",
            " 0.7767071783137115\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "\n",
        "# See what type of object the best_estimator_property is\n",
        "print(type(grid_rf_class.best_estimator_))\n",
        "\n",
        "# Create an array of predictions directly using the best_estimator_property\n",
        "predictions = grid_rf_class.best_estimator_.predict(X_test)\n",
        "\n",
        "# Take a look to confirm it worked, this should be an array of 1's and 0's\n",
        "print(predictions[0:5])\n",
        "\n",
        "# Now create a confusion matrix\n",
        "print(\"Confusion Matrix \\n\", confusion_matrix(y_test, predictions))\n",
        "\n",
        "# Get the ROC-AUC score\n",
        "predictions_proba = grid_rf_class.best_estimator_.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC-AUC Score \\n\", roc_auc_score(y_test, predictions_proba))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `.best_estimator_` property is a really powerful property to understand for streamlining your machine learning model building process. You now can run a grid search and seamlessly use the best model from that search to make predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
