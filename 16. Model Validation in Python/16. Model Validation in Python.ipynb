{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Modeling in scikit-learn\n",
    "> Before we can validate models, we need an understanding of how to create and work with them. This chapter provides an introduction to running regression and classification models in scikit-learn. We will use this model building foundation throughout the remaining chapters. This is the Summary of lecture \"Model Validation in Python\", via datacamp.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, Datacamp, Machine_Learning]\n",
    "- image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to model validation\n",
    "- Model validation\n",
    "    - Ensuring your model performs as expected on new data\n",
    "    - Testing model performance on holdout datasets\n",
    "    - Selecting the best model, parameters, and accuracy metrics\n",
    "    - Achieving the best accuracy for the given data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seen vs. unseen data\n",
    "Model's tend to have higher accuracy on observations they have seen before. In the candy dataset, predicting the popularity of Skittles will likely have higher accuracy than predicting the popularity of Andes Mints; Skittles is in the dataset, and Andes Mints is not.\n",
    "\n",
    "You've built a model based on 50 candies using the dataset `X_train` and need to report how accurate the model is at predicting the popularity of the 50 candies the model was built on, and the 35 candies (`X_test`) it has never seen. You will use the mean absolute error, `mae()`, as the accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorname</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>winpercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100 Grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>66.971725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Musketeers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.511</td>\n",
       "      <td>67.602936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One dime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.116</td>\n",
       "      <td>32.261086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One quarter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.511</td>\n",
       "      <td>46.116505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Heads</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.511</td>\n",
       "      <td>52.341465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  competitorname  chocolate  fruity  caramel  peanutyalmondy  nougat  \\\n",
       "0      100 Grand          1       0        1               0       0   \n",
       "1   3 Musketeers          1       0        0               0       1   \n",
       "2       One dime          0       0        0               0       0   \n",
       "3    One quarter          0       0        0               0       0   \n",
       "4      Air Heads          0       1        0               0       0   \n",
       "\n",
       "   crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n",
       "0                 1     0    1         0         0.732         0.860   \n",
       "1                 0     0    1         0         0.604         0.511   \n",
       "2                 0     0    0         0         0.011         0.116   \n",
       "3                 0     0    0         0         0.011         0.511   \n",
       "4                 0     0    0         0         0.906         0.511   \n",
       "\n",
       "   winpercent  \n",
       "0   66.971725  \n",
       "1   67.602936  \n",
       "2   32.261086  \n",
       "3   46.116505  \n",
       "4   52.341465  "
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy = pd.read_csv('candy-data.csv')\n",
    "candy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = candy.drop(['competitorname', 'winpercent'], axis=1)\n",
    "y = candy['winpercent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    chocolate  fruity  caramel  peanutyalmondy  nougat  crispedricewafer  \\\n",
       "0           1       0        1               0       0                 1   \n",
       "1           1       0        0               0       1                 0   \n",
       "2           0       0        0               0       0                 0   \n",
       "3           0       0        0               0       0                 0   \n",
       "4           0       1        0               0       0                 0   \n",
       "..        ...     ...      ...             ...     ...               ...   \n",
       "80          0       1        0               0       0                 0   \n",
       "81          0       1        0               0       0                 0   \n",
       "82          0       1        0               0       0                 0   \n",
       "83          0       0        1               0       0                 0   \n",
       "84          1       0        0               0       0                 1   \n",
       "\n",
       "    hard  bar  pluribus  sugarpercent  pricepercent  \n",
       "0      0    1         0         0.732         0.860  \n",
       "1      0    1         0         0.604         0.511  \n",
       "2      0    0         0         0.011         0.116  \n",
       "3      0    0         0         0.011         0.511  \n",
       "4      0    0         0         0.906         0.511  \n",
       "..   ...  ...       ...           ...           ...  \n",
       "80     0    0         0         0.220         0.116  \n",
       "81     1    0         0         0.093         0.116  \n",
       "82     0    0         1         0.313         0.313  \n",
       "83     1    0         0         0.186         0.267  \n",
       "84     0    0         1         0.872         0.848  \n",
       "\n",
       "[85 rows x 11 columns]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model error on seen data: 3.47.\n",
      "Model error on unseen data: 10.02.\n"
     ]
    }
   ],
   "source": [
    "# The model is fit using X_train and y_train\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# Create vectors of predictions\n",
    "train_predictions = model.predict(X_train)\n",
    "test_predictions = model.predict(X_test)\n",
    " \n",
    "# Train/Test Errors\n",
    "train_error = mae(y_true=y_train, y_pred=train_predictions)\n",
    "test_error = mae(y_true=y_test, y_pred=test_predictions)\n",
    " \n",
    "# Print the accuracy for seen and unseen data\n",
    "print(\"Model error on seen data: {0:.2f}.\".format(train_error))\n",
    "print(\"Model error on unseen data: {0:.2f}.\".format(test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When models perform differently on training and testing data, you should look to model validation to ensure you have the best performing model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression models\n",
    "- Random forest parameters\n",
    "    - `n_estimators`: the number of trees in the forest\n",
    "    - `max_depth`: the maximum depth of the trees\n",
    "    - `random_state`: random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters and fit a model\n",
    "Predictive tasks fall into one of two categories: regression or classification. In the candy dataset, the outcome is a continuous variable describing how often the candy was chosen over another candy in a series of 1-on-1 match-ups. To predict this value (the win-percentage), you will use a **regression** model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=6, random_state=1111)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=6, random_state=1111)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=6, random_state=1111)"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the number of trees\n",
    "rfr.n_estimators = 100\n",
    "\n",
    "# Add a maximum depth\n",
    "rfr.max_depth = 6\n",
    "\n",
    "# Set the random date\n",
    "rfr.random_state = 1111\n",
    "\n",
    "# Fit the model\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have updated parameters after the model was initialized. This approach is helpful when you need to update parameters. Before making predictions, let's see which candy characteristics were most important to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances\n",
    "Although some candy attributes, such as chocolate, may be extremely popular, it doesn't mean they will be important to model prediction. After a random forest model has been fit, you can review the model's attribute, `.feature_importances_`, to see which variables had the biggest impact. You can check how important each variable was in the model by looping over the feature importance array using `enumerate()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chocolate: 0.46\n",
      "fruity: 0.05\n",
      "caramel: 0.00\n",
      "peanutyalmondy: 0.08\n",
      "nougat: 0.00\n",
      "crispedricewafer: 0.01\n",
      "hard: 0.02\n",
      "bar: 0.00\n",
      "pluribus: 0.01\n",
      "sugarpercent: 0.16\n",
      "pricepercent: 0.20\n"
     ]
    }
   ],
   "source": [
    "# Print how important each column is to the model\n",
    "for i, item in enumerate(rfr.feature_importances_):\n",
    "    # Use i and item to print out the feature importance of each column\n",
    "    print(\"{0:s}: {1:.2f}\".format(X_train.columns[i], item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No surprise here - chocolate is the most important variable. `.feature_importances_` is a great way to see which variables were important to your random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification predictions\n",
    "In model validation, it is often important to know more about the predictions than just the final classification. When predicting who will win a game, most people are also interested in how likely it is a team will win.\n",
    "\n",
    "| Probability      | Prediction | Meaning |\n",
    "| ----------- | ----------- | ---------- |\n",
    "| 0 < .5      | 0       | Team Loses |\n",
    "| .5 < 1   | 1        | Team Wins |\n",
    "\n",
    "In this exercise, you look at the methods, `.predict()` and `.predict_proba()` using the `tic_tac_toe` dataset. The first method will give a prediction of whether Player One will win the game, and the second method will provide the probability of Player One winning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-Left</th>\n",
       "      <th>Top-Middle</th>\n",
       "      <th>Top-Right</th>\n",
       "      <th>Middle-Left</th>\n",
       "      <th>Middle-Middle</th>\n",
       "      <th>Middle-Right</th>\n",
       "      <th>Bottom-Left</th>\n",
       "      <th>Bottom-Middle</th>\n",
       "      <th>Bottom-Right</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Top-Left Top-Middle Top-Right Middle-Left Middle-Middle Middle-Right  \\\n",
       "0        x          x         x           x             o            o   \n",
       "1        x          x         x           x             o            o   \n",
       "2        x          x         x           x             o            o   \n",
       "3        x          x         x           x             o            o   \n",
       "4        x          x         x           x             o            o   \n",
       "\n",
       "  Bottom-Left Bottom-Middle Bottom-Right     Class  \n",
       "0           x             o            o  positive  \n",
       "1           o             x            o  positive  \n",
       "2           o             o            x  positive  \n",
       "3           o             b            b  positive  \n",
       "4           b             o            b  positive  "
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic_tac_toe = pd.read_csv('tic-tac-toe.csv')\n",
    "tic_tac_toe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tic_tac_toe['Class'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "X = tic_tac_toe.drop('Class', axis=1)\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8)\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    578\n",
      "0    189\n",
      "Name: count, dtype: int64\n",
      "The first predicted probabilities are: [0.4 0.6]\n"
     ]
    }
   ],
   "source": [
    "# Fit the rfc model\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Create arrays of predictions\n",
    "classification_predictions = rfc.predict(X_test)\n",
    "probability_predictions = rfc.predict_proba(X_test)\n",
    "\n",
    "# Print out count of binary predictions\n",
    "print(pd.Series(classification_predictions).value_counts())\n",
    "\n",
    "# Print the first value from probability_predictions\n",
    "print('The first predicted probabilities are: {}'.format(probability_predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see there were 563 observations where Player One was predicted to win the Tic-Tac-Toe game. Also, note that the `predicted_probabilities` array contains lists with only two values because you only have two possible responses (win or lose). Remember these two methods, as you will use them a lot throughout this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing model parameters\n",
    "Replicating model performance is vital in model validation. Replication is also important when sharing models with co-workers, reusing models on new data or asking questions on a website such as [Stack Overflow](https://stackoverflow.com/). You might use such a site to ask other coders about model errors, output, or performance. The best way to do this is to replicate your work by reusing model parameters.\n",
    "\n",
    "In this exercise, you use various methods to recall which parameters were used in a model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=6, n_estimators=50, random_state=1111)\n",
      "The random state is: 1111\n",
      "Printing the parameters dictionary: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)\n",
    "\n",
    "# Print the classification model\n",
    "print(rfc)\n",
    "\n",
    "# Print the classification model's random state parameter\n",
    "print('The random state is: {}'.format(rfc.random_state))\n",
    "\n",
    "# Print all parameters\n",
    "print('Printing the parameters dictionary: {}'.format(rfc.get_params()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalling which parameters were used will be helpful going forward. Model validation and performance rely heavily on which parameters were used, and there is no way to replicate a model without keeping track of the parameters used!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier\n",
    "This exercise reviews the four modeling steps discussed throughout this chapter using a random forest classification model. You will:\n",
    "\n",
    "1. Create a random forest classification model.\n",
    "2. Fit the model using the tic_tac_toe dataset.\n",
    "3. Make predictions on whether Player One will win (1) or lose (0) the current game.\n",
    "4. Finally, you will evaluate the overall accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0]\n",
      "0.7926988265971316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)\n",
    "\n",
    "# Fit rfc using X_train and y_train\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Create predictions on X_test\n",
    "predictions = rfc.predict(X_test)\n",
    "print(predictions[0:5])\n",
    "\n",
    "# Print model accuracy using score() and the testing data\n",
    "print(rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all the steps! Notice the first five predictions were all 1, indicating that Player One is predicted to win all five of those games. You also see the model accuracy was only 82%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Basics\n",
    "> This chapter focuses on the basics of model validation. From splitting data into training, validation, and testing datasets, to creating an understanding of the bias-variance tradeoff, we build the foundation for the techniques of K-Fold and Leave-One-Out validation practiced in chapter three. This is the Summary of lecture \"Model Validation in Python\", via datacamp.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, Datacamp, Machine_Learning]\n",
    "- image: images/train_test_score.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train,test, and validation datasets\n",
    "- Traditional train/test split\n",
    "    - Seen data (used for training)\n",
    "    - Unseen data (unavailable for training)\n",
    "![holdout](image/holdout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create one holdout set\n",
    "Your boss has asked you to create a simple random forest model on the `tic_tac_toe` dataset. She doesn't want you to spend much time selecting parameters; rather she wants to know how well the model will perform on future data. For future Tic-Tac-Toe games, it would be nice to know if your model can predict which player will win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-Left</th>\n",
       "      <th>Top-Middle</th>\n",
       "      <th>Top-Right</th>\n",
       "      <th>Middle-Left</th>\n",
       "      <th>Middle-Middle</th>\n",
       "      <th>Middle-Right</th>\n",
       "      <th>Bottom-Left</th>\n",
       "      <th>Bottom-Middle</th>\n",
       "      <th>Bottom-Right</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Top-Left Top-Middle Top-Right Middle-Left Middle-Middle Middle-Right  \\\n",
       "0        x          x         x           x             o            o   \n",
       "1        x          x         x           x             o            o   \n",
       "2        x          x         x           x             o            o   \n",
       "3        x          x         x           x             o            o   \n",
       "4        x          x         x           x             o            o   \n",
       "\n",
       "  Bottom-Left Bottom-Middle Bottom-Right     Class  \n",
       "0           x             o            o  positive  \n",
       "1           o             x            o  positive  \n",
       "2           o             o            x  positive  \n",
       "3           o             b            b  positive  \n",
       "4           b             o            b  positive  "
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic_tac_toe = pd.read_csv('tic-tac-toe.csv')\n",
    "tic_tac_toe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create dummy variables using pandas\n",
    "X = pd.get_dummies(tic_tac_toe.iloc[:, 0:9])\n",
    "y = tic_tac_toe.iloc[:, 9]\n",
    "\n",
    "# Create training and testing datasets, Use 10% for the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create two holdout sets\n",
    "You recently created a simple random forest model to predict Tic-Tac-Toe game wins for your boss, and at her request, you did not do any parameter tuning. Unfortunately, the overall model accuracy was too low for her standards. This time around, she has asked you to focus on model performance.\n",
    "\n",
    "Before you start testing different models and parameter sets, you will need to split the data into training, validation, and testing datasets. Remember that after splitting the data into training and testing datasets, the validation dataset is created by splitting the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary training and final testing datasets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "\n",
    "# Create the final training and validation datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, \n",
    "                                                  test_size=0.25, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have training, validation, and testing datasets, but do you know when you need both validation and testing datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy metrics: regression models\n",
    "- Mean absolute error (MAE)\n",
    "$$ \\text{MAE} = \\frac{\\sum_{i=1}^{n} \\vert y_i - \\hat{y_i} \\vert}{n} $$\n",
    "    - Simplest and most intuitive metric\n",
    "    - Treats all points equally\n",
    "    - Not sensitive to outliers\n",
    "- Mean squared error (MSE)\n",
    "$$ \\text{MSE} = \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2}{n} $$\n",
    "    - Most widely used regression metric\n",
    "    - Allows outlier errors to contribute more to the overall error\n",
    "    - Random family road trips could lead to large errors in predictions\n",
    "- MAE vs. MSE\n",
    "    - Accuracy metrics are always application apecific\n",
    "    - MAE and MSE error terms are in different units and should not be compared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean absolute error\n",
    "Communicating modeling results can be difficult. However, most clients understand that on average, a predictive model was off by some number. This makes explaining the mean absolute error easy. For example, when predicting the number of wins for a basketball team, if you predict 42, and they end up with 40, you can easily explain that the error was two wins.\n",
    "\n",
    "In this exercise, you are interviewing for a new position and are provided with two arrays. `y_test`, the true number of wins for all 30 NBA teams in 2017 and `predictions`, which contains a prediction for each team. To test your understanding, you are asked to both manually calculate the MAE and use `sklearn`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([53, 51, 51, 49, 43, 42, 42, 41, 41, 37, 36, 31, 29, 28, 20, 67, 61,\n",
    "       55, 51, 51, 47, 43, 41, 40, 34, 33, 32, 31, 26, 24])\n",
    "\n",
    "predictions = np.array([60, 62, 42, 42, 30, 50, 52, 42, 44, 35, 30, 30, 35, 40, 15, 72, 58,\n",
    "       60, 40, 42, 45, 46, 40, 35, 25, 40, 20, 34, 25, 24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a manual calculation, the error is 5.9\n",
      "Using scikit-learn, the error is 5.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Manually calculate the MAE\n",
    "n = len(predictions)\n",
    "mae_one = sum(abs(y_test - predictions)) / n\n",
    "print('With a manual calculation, the error is {}'.format(mae_one))\n",
    "\n",
    "# Use scikit-learn to calculate the MAE\n",
    "mae_two = mean_absolute_error(y_test, predictions)\n",
    "print('Using scikit-learn, the error is {}'.format(mae_two))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These predictions were about six wins off on average. This isn't too bad considering NBA teams play 82 games a year. Let's see how these errors would look if you used the mean squared error instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean squared error\n",
    "Let's focus on the 2017 NBA predictions again. Every year, there are at least a couple of NBA teams that win way more games than expected. If you use the MAE, this accuracy metric does not reflect the bad predictions as much as if you use the MSE. Squaring the large errors from bad predictions will make the accuracy look worse.\n",
    "\n",
    "In this example, NBA executives want to better predict team wins. You will use the mean squared error to calculate the prediction error. The actual wins are loaded as `y_test` and the `predictions` as predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a manual calculation, the error is 49.1\n",
      "Using scikit-learn, the error is 49.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "n = len(predictions)\n",
    "# Finish the manual calculation of the MSE\n",
    "mse_one = sum((y_test - predictions) ** 2) / n\n",
    "print('With a manual calculation, the error is {}'.format(mse_one))\n",
    "\n",
    "# Use the scikit-learn function to calculate MSE\n",
    "mse_two = mean_squared_error(y_test, predictions)\n",
    "print('Using scikit-learn, the error is {}'.format(mse_two))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run any additional models, you will try to beat an MSE of 49.1, which is the average squared error of using your model. Although the MSE is not as interpretable as the MAE, it will help us select a model that has fewer 'large' errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on data subsets\n",
    "In professional basketball, there are two conferences, the East and the West. Coaches and fans often only care about how teams in their own conference will do this year.\n",
    "\n",
    "You have been working on an NBA prediction model and would like to determine if the predictions were better for the East or West conference. You added a third array to your data called `labels`, which contains an \"E\" for the East teams, and a \"W\" for the West. `y_test` and `predictions` have again been loaded for your use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= np.array(['E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
    "       'E', 'E', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W',\n",
    "       'W', 'W', 'W', 'W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE for East teams is 6.733333333333333\n",
      "The MAE for West teams is 5.066666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "# Find the East conference teams\n",
    "east_teams = labels == 'E'\n",
    "\n",
    "# Create arrays for the true and predicted values\n",
    "true_east = y_test[east_teams]\n",
    "preds_east = predictions[east_teams]\n",
    "\n",
    "west_teams = labels == 'W'\n",
    "true_west = y_test[west_teams]\n",
    "preds_west = predictions[west_teams]\n",
    "\n",
    "# Print the accuracy metrics\n",
    "print('The MAE for East teams is {}'.format(mae(true_east, preds_east)))\n",
    "\n",
    "# Print the west accuracy\n",
    "print('The MAE for West teams is {}'.format(mae(true_west, preds_west)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It looks like the Western conference predictions were about two games better on average. Over the past few seasons, the Western teams have generally won the same number of games as the experts have predicted. Teams in the East are just not as predictable as those in the West."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification metrics\n",
    "- Types:\n",
    "    - Precision\n",
    "    - Recall (also called sensitivity)\n",
    "    - Accuracy\n",
    "    - Specificity\n",
    "    - F1-score and its variations\n",
    "- Confusion Matrix\n",
    "    - True Positive: Predict/Actual are both 1\n",
    "    - True Negative: Predict/Actual are both 0\n",
    "    - False Positive: Predicted 1, actual 0\n",
    "    - False Negative: Predicted 0, actual 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrices\n",
    "Confusion matrices are a great way to start exploring your model's accuracy. They provide the values needed to calculate a wide range of metrics, including sensitivity, specificity, and the F1-score.\n",
    "\n",
    "You have built a classification model to predict if a person has a broken arm based on an X-ray image. On the testing set, you have the following confusion matrix:\n",
    "\n",
    "|        |  Prediction: 0 | Prediction: 1 |\n",
    "| ------ | -------------- | ------------- |\n",
    "| Actual: 0 | 324 (TN) | 15 (FP) |\n",
    "| Actual: 1 | 123 (FN) | 491(TP) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy is  0.86\n",
      "The precision is  0.97\n",
      "The recall is  0.80\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the accuracy\n",
    "accuracy = (324 + 491) / (953)\n",
    "print(\"The overall accuracy is {0: 0.2f}\".format(accuracy))\n",
    "\n",
    "# Calculate and print the precision\n",
    "precision = (491) / (15 + 491)\n",
    "print(\"The precision is {0: 0.2f}\".format(precision))\n",
    "\n",
    "# Calculate and print the recall\n",
    "recall = (491) / (123 + 491)\n",
    "print(\"The recall is {0: 0.2f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, a true positive is a picture of an actual broken arm that was also predicted to be broken. Doctors are okay with a few additional false positives (predicted broken, not actually broken), as long as you don't miss anyone who needs immediate medical attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrices, again\n",
    "Creating a confusion matrix in Python is simple. The biggest challenge will be making sure you understand the orientation of the matrix. This exercise makes sure you understand the `sklearn` implementation of confusion matrices. Here, you have created a random forest model using the `tic_tac_toe` dataset `rfc` to predict outcomes of 0 (loss) or 1 (a win) for Player One.\n",
    "\n",
    "Note: If you read about confusion matrices on another website or for another programming language, the values might be reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic_tac_toe = pd.read_csv('tic-tac-toe.csv')\n",
    "# Create dummy variables using pandas\n",
    "X = pd.get_dummies(tic_tac_toe.iloc[:, 0:9])\n",
    "y = tic_tac_toe.iloc[:, 9]\n",
    "y = tic_tac_toe['Class'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "# Create training and testing datasets, Use 10% for the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=500, random_state=1111)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=500, random_state=1111)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=1111)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=500, random_state=1111)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  2]\n",
      " [ 0 66]]\n",
      "The number of true positives is: 66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create predictions\n",
    "test_predictions = rfc.predict(X_test)\n",
    "\n",
    "# Create and print the confusion matrix\n",
    "cm = confusion_matrix(y_test, test_predictions)\n",
    "print(cm)\n",
    "\n",
    "# Print the true positives (actual 1s that were predicted 1s)\n",
    "print(\"The number of true positives is: {}\".format(cm[1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row 1, column 1 represents the number of actual 1s that were predicted 1s (the true positives). Always make sure you understand the orientation of the confusion matrix before you start using it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision vs. recall\n",
    "The accuracy metrics you use to evaluate your model should always be based on the specific application. For this example, let's assume you are a really sore loser when it comes to playing Tic-Tac-Toe, but only when you are certain that you are going to win.\n",
    "\n",
    "Choose the most appropriate accuracy metric, either precision or recall, to complete this example. But remember, if you think you are going to win, you better win!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision value is 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "test_predictions = rfc.predict(X_test)\n",
    "\n",
    "# Create precision or recall score based on the metric you imported\n",
    "score = precision_score(y_test, test_predictions)\n",
    "\n",
    "# Print the final result\n",
    "print(\"The precision value is {0:.2f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision value is 0.97, The recall value is 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "test_predictions = rfc.predict(X_test)\n",
    "\n",
    "# Create precision score based on the metric\n",
    "p_score = precision_score(y_test, test_predictions)\n",
    "r_score = recall_score(y_test, test_predictions)\n",
    "\n",
    "# Print the final result\n",
    "print('The precision value is {0:.2f}, The recall value is {1:.2f}'.format(p_score, r_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The bias-variance tradeoff\n",
    "- Variance\n",
    "    - Following the training data too closely\n",
    "    - Fails to generalize to the test data\n",
    "    - Low training error but high test error\n",
    "    - Occurs when models are overfit and have high complexity\n",
    "    - High variance makes over-fitting\n",
    "- Bias\n",
    "    - Failing to find the relationship between the data and the response\n",
    "    - High training/test error\n",
    "    - Occurs when models are underfit\n",
    "    - High bias makes under-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error due to under/over-fitting\n",
    "The candy dataset is prime for overfitting. With only 85 observations, if you use 20% for the testing dataset, you are losing a lot of vital data that could be used for modeling. Imagine the scenario where most of the chocolate candies ended up in the training data and very few in the holdout sample. Our model might only see that chocolate is a vital factor, but fail to find that other attributes are also important. In this exercise, you'll explore how using too many features (columns) in a random forest model can lead to overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "candy = pd.read_csv('candy-data.csv')\n",
    "\n",
    "X = candy.drop(['competitorname', 'winpercent'], axis=1)\n",
    "y = candy['winpercent']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is 3.90\n",
      "The testing error is 9.15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Update the rfr model\n",
    "rfr = RandomForestRegressor(n_estimators=25, random_state=1111, max_features=2)\n",
    "\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print the training and test accuracy\n",
    "print('The training error is {0:.2f}'.format(mae(y_train, rfr.predict(X_train))))\n",
    "print('The testing error is {0:.2f}'.format(mae(y_test, rfr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is 3.59\n",
      "The testing error is 10.00\n"
     ]
    }
   ],
   "source": [
    "# Update the rfr model\n",
    "rfr = RandomForestRegressor(n_estimators=25, random_state=1111, max_features=11)\n",
    "\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print the training and test accuracy\n",
    "print('The training error is {0:.2f}'.format(mae(y_train, rfr.predict(X_train))))\n",
    "print('The testing error is {0:.2f}'.format(mae(y_test, rfr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is 3.60\n",
      "The testing error is 8.79\n"
     ]
    }
   ],
   "source": [
    "# Update the rfr model\n",
    "rfr = RandomForestRegressor(n_estimators=25, random_state=1111, max_features=4)\n",
    "\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print the training and test accuracy\n",
    "print('The training error is {0:.2f}'.format(mae(y_train, rfr.predict(X_train))))\n",
    "print('The testing error is {0:.2f}'.format(mae(y_test, rfr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Am I underfitting?\n",
    "You are creating a random forest model to predict if you will win a future game of Tic-Tac-Toe. Using the `tic_tac_toe` dataset, you have created training and testing datasets, `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "\n",
    "You have decided to create a bunch of random forest models with varying amounts of trees (1, 2, 3, 4, 5, 10, 20, and 50). The more trees you use, the longer your random forest model will take to run. However, if you don't use enough trees, you risk underfitting. You have created a for loop to test your model at the different number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables using pandas\n",
    "X = pd.get_dummies(tic_tac_toe.iloc[:, 0:9])\n",
    "y = tic_tac_toe.iloc[:, 9]\n",
    "y = tic_tac_toe['Class'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "# Create training and testing datasets, Use 10% for the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training scores were: [0.94, 0.93, 0.98, 0.97, 0.99, 1.0, 1.0, 1.0]\n",
      "The testing scores were: [0.83, 0.79, 0.89, 0.91, 0.91, 0.93, 0.97, 0.98]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_scores, train_scores = [], []\n",
    "for i in [1, 2, 3, 4, 5, 10, 20, 50]:\n",
    "    rfc = RandomForestClassifier(n_estimators=i, random_state=1111)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    # Create predictions for the X_train and X_test datasets\n",
    "    train_predictions = rfc.predict(X_train)\n",
    "    test_predictions = rfc.predict(X_test)\n",
    "    \n",
    "    # Append the accuracy score for the test and train predictions\n",
    "    train_scores.append(round(accuracy_score(y_train, train_predictions), 2))\n",
    "    test_scores.append(round(accuracy_score(y_test, test_predictions), 2))\n",
    "    \n",
    "# Print the train and test scores\n",
    "print(\"The training scores were: {}\".format(train_scores))\n",
    "print(\"The testing scores were: {}\".format(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that with only one tree, both the train and test scores are low. As you add more trees, both errors improve. Even at 50 trees, this still might not be enough. Every time you use more trees, you achieve higher accuracy. At some point though, more trees increase training time, but do not decrease testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [1, 2, 3, 4, 5, 10, 20, 50]\n",
    "tmp = pd.DataFrame({'x':x, 'training':train_scores, 'test':test_scores})\n",
    "tmp.set_index('x', inplace=True)\n",
    "tmp.plot(title='train/test score for n_estimators');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "> Holdout sets are a great start to model validation. However, using a single train and test set if often not enough. Cross-validation is considered the gold standard when it comes to validating model performance and is almost always used when tuning model hyper-parameters. This chapter focuses on performing cross-validation to validate model performance. This is the Summary of lecture \"Model Validation in Python\", via datacamp.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, Datacamp, Machine_Learning]\n",
    "- image: images/loocv.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problems with holdout sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two samples\n",
    "After building several classification models based on the `tic_tac_toe` dataset, you realize that some models do not generalize as well as others. You have created training and testing splits just as you have been taught, so you are curious why your validation process is not working.\n",
    "\n",
    "After trying a different training, test split, you noticed differing accuracies for your machine learning model. Before getting too frustrated with the varying results, you have decided to see what else could be going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-Left</th>\n",
       "      <th>Top-Middle</th>\n",
       "      <th>Top-Right</th>\n",
       "      <th>Middle-Left</th>\n",
       "      <th>Middle-Middle</th>\n",
       "      <th>Middle-Right</th>\n",
       "      <th>Bottom-Left</th>\n",
       "      <th>Bottom-Middle</th>\n",
       "      <th>Bottom-Right</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Top-Left Top-Middle Top-Right Middle-Left Middle-Middle Middle-Right  \\\n",
       "0        x          x         x           x             o            o   \n",
       "1        x          x         x           x             o            o   \n",
       "2        x          x         x           x             o            o   \n",
       "3        x          x         x           x             o            o   \n",
       "4        x          x         x           x             o            o   \n",
       "\n",
       "  Bottom-Left Bottom-Middle Bottom-Right     Class  \n",
       "0           x             o            o  positive  \n",
       "1           o             x            o  positive  \n",
       "2           o             o            x  positive  \n",
       "3           o             b            b  positive  \n",
       "4           b             o            b  positive  "
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic_tac_toe = pd.read_csv('tic-tac-toe.csv')\n",
    "tic_tac_toe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Class\n",
      "positive    134\n",
      "negative     66\n",
      "Name: count, dtype: int64\n",
      "Class\n",
      "positive    123\n",
      "negative     77\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create two different samples of 200 observations\n",
    "sample1 = tic_tac_toe.sample(n=200, random_state=1111)\n",
    "sample2 = tic_tac_toe.sample(n=200, random_state=1171)\n",
    "\n",
    "# Print the number of common observations\n",
    "print(len([index for index in sample1.index if index in sample2.index]))\n",
    "\n",
    "# Print the number of observations in the Class column for both samples\n",
    "print(sample1['Class'].value_counts())\n",
    "print(sample2['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are a varying number of positive observations for both sample test sets. Sometimes creating a single test holdout sample is not enough to achieve the high levels of model validation you want. You need to use something more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn's KFold()\n",
    "You just finished running a colleagues code that creates a random forest model and calculates an out-of-sample accuracy. You noticed that your colleague's code did not have a random state, and the errors you found were completely different than the errors your colleague reported.\n",
    "\n",
    "To get a better estimate for how accurate this random forest model will be on new data, you have decided to generate some indices to use for KFold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorname</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>winpercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100 Grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>66.971725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Musketeers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.511</td>\n",
       "      <td>67.602936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One dime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.116</td>\n",
       "      <td>32.261086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One quarter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.511</td>\n",
       "      <td>46.116505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Heads</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.511</td>\n",
       "      <td>52.341465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  competitorname  chocolate  fruity  caramel  peanutyalmondy  nougat  \\\n",
       "0      100 Grand          1       0        1               0       0   \n",
       "1   3 Musketeers          1       0        0               0       1   \n",
       "2       One dime          0       0        0               0       0   \n",
       "3    One quarter          0       0        0               0       0   \n",
       "4      Air Heads          0       1        0               0       0   \n",
       "\n",
       "   crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n",
       "0                 1     0    1         0         0.732         0.860   \n",
       "1                 0     0    1         0         0.604         0.511   \n",
       "2                 0     0    0         0         0.011         0.116   \n",
       "3                 0     0    0         0         0.011         0.511   \n",
       "4                 0     0    0         0         0.906         0.511   \n",
       "\n",
       "   winpercent  \n",
       "0   66.971725  \n",
       "1   67.602936  \n",
       "2   32.261086  \n",
       "3   46.116505  \n",
       "4   52.341465  "
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy = pd.read_csv('candy-data.csv')\n",
    "candy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = candy.drop(['competitorname', 'winpercent'], axis=1).to_numpy()\n",
    "y = candy['winpercent'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Use KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1111)\n",
    "\n",
    "# Create splits\n",
    "splits = kf.split(X)\n",
    "\n",
    "# Print the number of indices\n",
    "for train_index, val_index in splits:\n",
    "    print(\"Number of training indices: %s\" % len(train_index))\n",
    "    print(\"Number of validation indices: %s\" % len(val_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 85 rows. You have created five splits - each containing 68 training and 17 validation indices. You can use these indices to complete 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using KFold indices\n",
    "You have already created `splits`, which contains indices for the candy-data dataset to complete 5-fold cross-validation. To get a better estimate for how well a colleague's random forest model will perform on a new data, you want to run this model on the five different training and validation indices you just created.\n",
    "\n",
    "In this exercise, you will use these indices to check the accuracy of this model using the five different splits. A for loop has been provided to assist with this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splits\n",
    "splits = kf.split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split accuracy: 150.99298148707666\n",
      "Split accuracy: 171.22206240542593\n",
      "Split accuracy: 131.72569156195593\n",
      "Split accuracy: 80.61940183841385\n",
      "Split accuracy: 221.63020627476214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
    "\n",
    "# Access the training and validation indices of splits\n",
    "for train_index, val_index in splits:\n",
    "    # Setup the training and validation data\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_val, y_val = X[val_index], y[val_index]\n",
    "    \n",
    "    # Fit the random forest model\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions, and print the accuracy\n",
    "    predictions = rfc.predict(X_val)\n",
    "    print(\"Split accuracy: \" + str(mean_squared_error(y_val, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`KFold()` is a great method for accessing individual indices when completing cross-validation. One drawback is needing a for loop to work through the indices though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn's cross_val_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn's methods\n",
    "You have decided to build a regression model to predict the number of new employees your company will successfully hire next month. You open up a new Python script to get started, but you quickly realize that sklearn has a lot of different modules. Let's make sure you understand the names of the modules, the methods, and which module contains which method.\n",
    "\n",
    "Follow the instructions below to load in all of the necessary methods for completing cross-validation using sklearn. You will use modules:\n",
    "\n",
    "- metrics\n",
    "- model_selection\n",
    "- ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cross_val_score from model_selection module\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Instruction 1: Load the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instruction 2: Load the random forest regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instruction 3: Load the mean squared error method\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Instruction 4: Load the function for creating a scorer\n",
    "from sklearn.metrics import make_scorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement cross_val_score()\n",
    "Your company has created several new candies to sell, but they are not sure if they should release all five of them. To predict the popularity of these new candies, you have been asked to build a regression model using the candy dataset. Remember that the response value is a head-to-head win-percentage against other candies.\n",
    "\n",
    "Before you begin trying different regression models, you have decided to run cross-validation on a simple random forest model to get a baseline error to compare with any future results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.30323056938693\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "# Setup cross_val_score\n",
    "cv = cross_val_score(estimator=rfc, X=X_train, y=y_train, cv=10, scoring=mse)\n",
    "\n",
    "# Print the mean error\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a baseline score to build on. If you decide to build additional models or try new techniques, you should try to get an error lower than 155.56. Lower errors indicate that your popularity predictions are improving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-one-out-cross-validation (LOOCV)\n",
    "- LOOCV\n",
    "- When to use LOOCV?\n",
    "    - The amount of training data is limited\n",
    "    - You want the absolute best error estimate for new data\n",
    "- Be cautious when:\n",
    "    - Computation resources are limited\n",
    "    - You have a lot of data\n",
    "    - You have a lot of parameters to test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-out-cross-validation\n",
    "Let's assume your favorite candy is not in the candy dataset, and that you are interested in the popularity of this candy. Using 5-fold cross-validation will train on only 80% of the data at a time. The candy dataset only has 85 rows though, and leaving out 20% of the data could hinder our model. However, using leave-one-out-cross-validation allows us to make the most out of our limited dataset and will give you the best estimate for your favorite candy's popularity!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the errors is: 0.07014613778705638.\n",
      "The standard deviation of the errors is: 0.12079897928668414.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Create scorer\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "# Instantiate the RandomForestRegressor model\n",
    "rfr = RandomForestRegressor(n_estimators=15, random_state=1111)\n",
    "\n",
    "# Define cv for LOOCV\n",
    "cv = X.shape[0]  # Number of samples in X\n",
    "\n",
    "# Implement LOOCV\n",
    "scores = cross_val_score(rfr, X, y, cv=cv, scoring=mae_scorer)\n",
    "\n",
    "# Print the mean and standard deviation of errors\n",
    "print(\"The mean of the errors is: %s.\" % np.mean(scores))\n",
    "print(\"The standard deviation of the errors is: %s.\" % np.std(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have come along way with model validation techniques. The final chapter will wrap up model validation by discussing how to select the best model and give an introduction to parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best model with Hyperparameter tuning.\n",
    "> The first three chapters focused on model validation techniques. In chapter 4 we apply these techniques, specifically cross-validation, while learning about hyperparameter tuning. After all, model validation makes tuning possible and helps us select the overall best model. This is the Summary of lecture \"Model Validation in Python\", via datacamp.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, Datacamp, Machine_Learning]\n",
    "- image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to hyperparameter tuning\n",
    "- Model Parameters\n",
    "    - Learned or estimated from the data\n",
    "    - The result of fitting a model\n",
    "    - Used when making future predictions\n",
    "    - Not manually set\n",
    "- Model Hyperparameters\n",
    "    - Manually set before the training occurs\n",
    "    - Specify how the training is supposed to happen\n",
    "- Hyperparameter tuning\n",
    "    - Select hyperparameters\n",
    "    - Run a single model type at different value sets\n",
    "    - Create ranges of possible values to select from\n",
    "    - Specify a single accuracy metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Hyperparameters\n",
    "For a school assignment, your professor has asked your class to create a random forest model to predict the average test score for the final exam.\n",
    "\n",
    "After developing an initial random forest model, you are unsatisfied with the overall accuracy. You realize that there are too many hyperparameters to choose from, and each one has a lot of possible values. You have decided to make a list of possible ranges for the hyperparameters you might use in your next model.\n",
    "\n",
    "Your professor has provided de-identified data for the last ten quizzes to act as the training data. There are 30 students in your class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators='warn', max_features='auto', random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 'warn', 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Review the parameters of rfr\n",
    "print(rfr.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum Depth\n",
    "max_depth = [4, 8, 12]\n",
    "\n",
    "# Minimum samples for a split\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Max features \n",
    "max_features = [4, 6, 8, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning requires selecting parameters to tune, as well the possible values these parameters can be set to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a model using ranges\n",
    "You have just finished creating a list of hyperparameters and ranges to use when tuning a predictive model for an assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 12, 'max_features': 6, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Fill in rfr using your variables\n",
    "rfr = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=random.sample(max_depth, 1)[0],\n",
    "    min_samples_split=random.sample(min_samples_split, 1)[0],\n",
    "    max_features = random.sample(max_features, 1)[0]\n",
    ")\n",
    "\n",
    "# Print out the parameters\n",
    "print(rfr.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV\n",
    "- Grid Search\n",
    "    - Benefits\n",
    "        - Tests every possible combination\n",
    "    - Drawbacks\n",
    "        - Additional hyperparameters increase training time exponentially\n",
    "- Alternatives\n",
    "    - Random searching\n",
    "    - Bayesian optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for RandomizedSearch\n",
    "Last semester your professor challenged your class to build a predictive model to predict final exam test scores. You tried running a few different models by randomly selecting hyperparameters. However, running each model required you to code it individually.\n",
    "\n",
    "After learning about `RandomizedSearchCV()`, you're revisiting your professors challenge to build the best model. In this exercise, you will prepare the three necessary inputs for completing a random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# Finish the dictionary by adding the max_depth parameter\n",
    "param_dist = {\n",
    "    \"max_depth\": [2, 4, 6, 8],\n",
    "    \"max_features\": [2, 4, 6, 8, 10],\n",
    "    \"min_samples_split\": [2, 4, 8, 16]\n",
    "}\n",
    "\n",
    "# Create a random forest regression model\n",
    "rfr = RandomForestRegressor(n_estimators=10, random_state=1111)\n",
    "\n",
    "# Create a scorer to use (use the mean squared error)\n",
    "scorer = make_scorer(mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `RandomizedSearchCV()`, you need a distribution dictionary, an estimator, and a scorer—once you've got these, you can run a random search to find the best parameters for your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing RandomizedSearchCV\n",
    "You are hoping that using a random search algorithm will help you improve predictions for a class assignment. You professor has challenged your class to predict the overall final exam average score.\n",
    "\n",
    "In preparation for completing a random search, you have created:\n",
    "\n",
    "- `param_dist`: the hyperparameter distributions\n",
    "- `rfr`: a random forest regression model\n",
    "- `scorer`: a scoring method to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Build a random search using param_dist, rfr, and scorer\n",
    "random_search = RandomizedSearchCV(estimator=rfr,\n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=10,\n",
    "                                   cv=5,\n",
    "                                   scoring=scorer\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it takes a lot of steps, hyperparameter tuning with random search is well worth it and can improve the accuracy of your models. Plus, you are already using cross-validation to validate your best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting your final model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best classification accuracy\n",
    "You are in a competition at work to build the best model for predicting the winner of a Tic-Tac-Toe game. You already ran a random search and saved the results of the most accurate model to `rs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic_tac_toe = pd.read_csv('tic-tac-toe.csv')\n",
    "# Create dummy variables using pandas\n",
    "X = pd.get_dummies(tic_tac_toe.iloc[:, 0:9])\n",
    "y = tic_tac_toe.iloc[:, 9]\n",
    "y = tic_tac_toe['Class'].apply(lambda x: 1 if x == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create a precision scorer\n",
    "precision = make_scorer(precision_score)\n",
    "\n",
    "# Finalize the random search\n",
    "rs = RandomizedSearchCV(\n",
    "  estimator=rfc, param_distributions=param_dist,\n",
    "  scoring=precision,\n",
    "  cv=5, n_iter=10, random_state=1111)\n",
    "rs.fit(X, y)\n",
    "\n",
    "# print the mean test scores:\n",
    "print('The accuracy for each run was: {}.'.format(rs.cv_results_['mean_test_score']))\n",
    "# print the best model score:\n",
    "print('The best accuracy for a single model was: {}'.format(rs.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result of random search, we can find that the optimal parameter is:\n",
    "```python\n",
    "{'n_estimators': 20, 'min_samples_split': 4, 'max_depth': 12}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best precision model\n",
    "Your boss has offered to pay for you to see three sports games this year. Of the 41 home games your favorite team plays, you want to ensure you go to three home games that they will definitely win. You build a model to decide which games your team will win.\n",
    "\n",
    "To do this, you will build a random search algorithm and focus on model precision (to ensure your team wins). You also want to keep track of your best model and best parameters, so that you can use them again next year (if the model does well, of course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = pd.read_csv('sports.csv')\n",
    "X = sports.drop('win', axis=1)\n",
    "y = sports['win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': range(2, 12, 2),\n",
    "    'min_samples_split': range(2, 12, 2),\n",
    "    'n_estimators': [10, 25, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for each run was: [0.89509109 0.74906134 0.67453379 0.88000479 0.91326898 0.87759948\n",
      " 0.67250658 0.8123614  0.90661588 0.89980419].\n",
      "The best accuracy for a single model was: 0.9132689845230185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Create a precision scorer\n",
    "precision = make_scorer(precision_score)\n",
    "\n",
    "# Finalize the random search\n",
    "rs = RandomizedSearchCV(estimator=rfc, param_distributions=param_dist,\n",
    "                        scoring=precision, cv=5, n_iter=10,\n",
    "                        random_state=1111)\n",
    "\n",
    "rs.fit(X, y)\n",
    "\n",
    "# Print the mean test scores:\n",
    "print('The accuracy for each run was: {}.'.format(rs.cv_results_['mean_test_score']))\n",
    "# Print the best model scores:\n",
    "print('The best accuracy for a single model was: {}'.format(rs.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model's precision was 91%! The best model accurately predicts a winning game 91% of the time. If you look at the mean test scores, you can tell some of the other parameter sets did really poorly. Also, since you used cross-validation, you can be confident in your predictions. Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
